Starting processing work
Changing directory
Start work
Updated the 'path' in /lunarc/nobackup/projects/lu2023-17-41/carl/LTU/LTU_Thesis_v2/cnet/cnet_dataset_80-10-10-page_800/c_data.yaml
New https://pypi.org/project/ultralytics/8.2.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'
Ultralytics YOLOv8.1.43 ðŸš€ Python-3.11.4 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100 80GB PCIe, 81038MiB)
[34m[1mengine/trainer: [0mtask=detect, mode=train, model=/lunarc/nobackup/projects/lu2023-17-41/carl/LTU/LTU_Thesis_v2/yolov8x.pt, data=/lunarc/nobackup/projects/lu2023-17-41/carl/LTU/LTU_Thesis_v2/cnet/cnet_dataset_80-10-10-page_800/c_data.yaml, epochs=250, time=None, patience=15, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=/lunarc/nobackup/projects/lu2023-17-41/carl/LTU/LTU_Thesis_v2/cnet/cnet_dataset_80-10-10-page_800/yolov8x, name=20240421_T1320_800, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=5.0, translate=0.1, scale=0.5, shear=5.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/lunarc/nobackup/projects/lu2023-17-41/carl/LTU/LTU_Thesis_v2/cnet/cnet_dataset_80-10-10-page_800/yolov8x/20240421_T1320_800
Overriding model.yaml nc=80 with nc=68

                   from  n    params  module                                       arguments                     
  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 
  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               
  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           
  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              
  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           
  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              
  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           
  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              
  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           
  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 
 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          
 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                
 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          
 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 
 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              
 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 
 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              
 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                
 22        [15, 18, 21]  1   8783452  ultralytics.nn.modules.head.Detect           [68, [320, 640, 640]]         
Model summary: 365 layers, 68218092 parameters, 68218076 gradients, 258.5 GFLOPs

Transferred 589/595 items from pretrained weights
[34m[1mTensorBoard: [0mStart with 'tensorboard --logdir /lunarc/nobackup/projects/lu2023-17-41/carl/LTU/LTU_Thesis_v2/cnet/cnet_dataset_80-10-10-page_800/yolov8x/20240421_T1320_800', view at http://localhost:6006/
Freezing layer 'model.22.dfl.conv.weight'
[34m[1mAMP: [0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...
[34m[1mAMP: [0mchecks passed âœ…
[34m[1mtrain: [0mNew cache created: /lunarc/nobackup/projects/lu2023-17-41/carl/LTU/LTU_Thesis_v2/data/dataset_80-10-10-page_800/c_data/train/labels.cache
[34m[1mval: [0mNew cache created: /lunarc/nobackup/projects/lu2023-17-41/carl/LTU/LTU_Thesis_v2/data/dataset_80-10-10-page_800/c_data/validation/labels.cache
Plotting labels to /lunarc/nobackup/projects/lu2023-17-41/carl/LTU/LTU_Thesis_v2/cnet/cnet_dataset_80-10-10-page_800/yolov8x/20240421_T1320_800/labels.jpg... 
[34m[1moptimizer:[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... 
[34m[1moptimizer:[0m SGD(lr=0.01, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)
[34m[1mTensorBoard: [0mmodel graph visualization added âœ…
Image sizes 640 train, 640 val
Using 8 dataloader workers
Logging results to [1m/lunarc/nobackup/projects/lu2023-17-41/carl/LTU/LTU_Thesis_v2/cnet/cnet_dataset_80-10-10-page_800/yolov8x/20240421_T1320_800[0m
Starting training for 250 epochs...

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.899      0.815      0.896      0.547

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.948      0.867      0.917      0.548

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.912      0.797       0.86      0.489

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.968      0.879      0.925      0.593

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.967      0.915      0.933      0.598

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.943      0.916      0.928      0.615

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.958      0.923      0.941      0.635

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.975      0.927      0.936      0.642

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.955      0.929       0.94      0.645

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767       0.98      0.928      0.941      0.649

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.955      0.921      0.935      0.648

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767       0.96       0.93       0.94      0.651

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.958      0.933      0.942      0.653

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.987      0.929      0.941      0.661

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.957      0.935      0.941      0.664

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.964      0.926      0.944      0.669

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.978      0.934       0.94      0.659

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.982      0.934      0.942      0.668

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.965      0.924       0.94      0.667

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767       0.98      0.939      0.942      0.662

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.962      0.935      0.943      0.672

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.987      0.935      0.943       0.67

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.978      0.936      0.943       0.67

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.976      0.938      0.941      0.667

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.979      0.938      0.942      0.666

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.955      0.935      0.941      0.667

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767       0.96      0.933       0.94      0.668

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767       0.93      0.936       0.94      0.667

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.933      0.934       0.94      0.664

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.933      0.937      0.941      0.665

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.933      0.937      0.941      0.663

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.946      0.939      0.941      0.664

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.947      0.939      0.941      0.664

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.953      0.927      0.941      0.665

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.953      0.927      0.941      0.664

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
                   all       3138       5767      0.953      0.926       0.94      0.662
[34m[1mEarlyStopping: [0mTraining stopped early as no improvement observed in last 15 epochs. Best results observed at epoch 21, best model saved as best.pt.
To update EarlyStopping(patience=15) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.

36 epochs completed in 3.785 hours.
Optimizer stripped from /lunarc/nobackup/projects/lu2023-17-41/carl/LTU/LTU_Thesis_v2/cnet/cnet_dataset_80-10-10-page_800/yolov8x/20240421_T1320_800/weights/last.pt, 136.8MB
Optimizer stripped from /lunarc/nobackup/projects/lu2023-17-41/carl/LTU/LTU_Thesis_v2/cnet/cnet_dataset_80-10-10-page_800/yolov8x/20240421_T1320_800/weights/best.pt, 136.8MB

Validating /lunarc/nobackup/projects/lu2023-17-41/carl/LTU/LTU_Thesis_v2/cnet/cnet_dataset_80-10-10-page_800/yolov8x/20240421_T1320_800/weights/best.pt...
Ultralytics YOLOv8.1.43 ðŸš€ Python-3.11.4 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100 80GB PCIe, 81038MiB)
Model summary (fused): 268 layers, 68189052 parameters, 0 gradients, 257.8 GFLOPs
                   all       3138       5767      0.961      0.936      0.943      0.673
                  0985       3138         99      0.968       0.99      0.989      0.825
                  0987       3138        101      0.988       0.95      0.967       0.85
                  0988       3138         92      0.976          1      0.986       0.86
                  0989       3138        235      0.995      0.987      0.994      0.816
                  098A       3138        177      0.999          1      0.995      0.817
                  098F       3138        101      0.989      0.941      0.979      0.662
                  0990       3138        106      0.991          1      0.995      0.848
                  0993       3138        101      0.997          1      0.995      0.986
                  0994       3138        116      0.972          1      0.994      0.826
                  0995       3138        114          1      0.993      0.995      0.667
                  0997       3138         44      0.988      0.932       0.98      0.652
                  0998       3138        104          1          1      0.995      0.769
                  0999       3138        336          1          0          0          0
                  099C       3138         86          1       0.98      0.992       0.69
                  099D       3138         45      0.956          1      0.995       0.66
                  099F       3138         92      0.908          1      0.995      0.854
                  09A0       3138        102          1      0.951      0.995      0.671
                  09A3       3138        100       0.99          1      0.995      0.684
                  09A4       3138         98      0.973      0.969       0.99      0.656
                  09A6       3138        194       0.98          1      0.995      0.617
                  09A7       3138        117      0.997          1      0.995      0.716
                  09A8       3138        141      0.979      0.986      0.994      0.614
                  09AA       3138        117      0.991      0.917      0.984      0.659
                  09AB       3138         84      0.996          1      0.995      0.769
                  09AC       3138        198      0.979      0.975      0.984      0.611
                  09AD       3138        107      0.951      0.944      0.956      0.639
                  09AE       3138        102          1      0.976      0.995      0.651
                  09B0       3138        611      0.982      0.944      0.966      0.597
                  09B2       3138        111      0.999      0.982       0.99      0.655
                  09B6       3138         99      0.998          1      0.995       0.78
                  09B7       3138        119      0.966      0.966      0.962      0.613
                  09B8       3138        209      0.979       0.99      0.991      0.639
                  09B9       3138         93      0.996      0.978       0.99      0.594
                  09DF       3138        117      0.926          1      0.994        0.8
                  0982       3138         98      0.948      0.933      0.954      0.506
                  09CE       3138         86      0.996          1      0.995      0.639
        09A8 09CD 09A6       3138         92          1      0.984      0.995      0.618
        0999 09CD 0997       3138        199          0          0          0          0
        09A8 09CD 09A4       3138        113      0.997          1      0.995      0.639
        0995 09CD 09B8       3138         89      0.997          1      0.995      0.609
        09A4 09CD 09A4       3138        112      0.973      0.973      0.971      0.583
        099F 09CD 099F       3138        106          1      0.922      0.995      0.812
        09B7 09CD 09A3       3138         97      0.998          1      0.995      0.669
        09A6 09CD 09A7       3138        107      0.989          1      0.994      0.791
Speed: 0.2ms preprocess, 1.9ms inference, 0.0ms loss, 0.6ms postprocess per image
Results saved to [1m/lunarc/nobackup/projects/lu2023-17-41/carl/LTU/LTU_Thesis_v2/cnet/cnet_dataset_80-10-10-page_800/yolov8x/20240421_T1320_800[0m
Ultralytics YOLOv8.1.43 ðŸš€ Python-3.11.4 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100 80GB PCIe, 81038MiB)
Model summary (fused): 268 layers, 68189052 parameters, 0 gradients, 257.8 GFLOPs

[34m[1mPyTorch:[0m starting from '/lunarc/nobackup/projects/lu2023-17-41/carl/LTU/LTU_Thesis_v2/cnet/cnet_dataset_80-10-10-page_800/yolov8x/20240421_T1320_800/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 72, 8400) (130.5 MB)

[34m[1mONNX:[0m starting export with onnx 1.15.0 opset 17...
[34m[1mONNX:[0m export success âœ… 1.7s, saved as '/lunarc/nobackup/projects/lu2023-17-41/carl/LTU/LTU_Thesis_v2/cnet/cnet_dataset_80-10-10-page_800/yolov8x/20240421_T1320_800/weights/best.onnx' (260.4 MB)

Export complete (2.3s)
Results saved to [1m/lunarc/nobackup/projects/lu2023-17-41/carl/LTU/LTU_Thesis_v2/cnet/cnet_dataset_80-10-10-page_800/yolov8x/20240421_T1320_800/weights[0m
Predict:         yolo predict task=detect model=/lunarc/nobackup/projects/lu2023-17-41/carl/LTU/LTU_Thesis_v2/cnet/cnet_dataset_80-10-10-page_800/yolov8x/20240421_T1320_800/weights/best.onnx imgsz=640  
Validate:        yolo val task=detect model=/lunarc/nobackup/projects/lu2023-17-41/carl/LTU/LTU_Thesis_v2/cnet/cnet_dataset_80-10-10-page_800/yolov8x/20240421_T1320_800/weights/best.onnx imgsz=640 data=/lunarc/nobackup/projects/lu2023-17-41/carl/LTU/LTU_Thesis_v2/cnet/cnet_dataset_80-10-10-page_800/c_data.yaml  
Visualize:       https://netron.app
Total training time: 13721.471675157547 seconds
Finished processing.
